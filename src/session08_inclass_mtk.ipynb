{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 8 - Language modelling with RNNs (Text Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 12:20:03.419601: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# data processing tools\n",
    "import string, os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# keras module for building LSTM \n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.keras.utils as ku \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# surpress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower() # make all text lowercase, keep strings that arent punctuation\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore') # utf8 encoding makes up for accents\n",
    "    return txt \n",
    "\n",
    "def get_sequence_of_tokens(tokenizer, corpus):\n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences\n",
    "\n",
    "def generate_padded_sequences(input_sequences):\n",
    "    # get the length of the longest sequence\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    # make every sequence the length of the longest on\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, \n",
    "                                            maxlen=max_sequence_len, \n",
    "                                            padding='pre'))\n",
    "\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, \n",
    "                            num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, \n",
    "                        10, \n",
    "                        input_length=input_len))\n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.1)) # remove 10% of the weight when the model is training\n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, \n",
    "                    activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                    optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], \n",
    "                                    maxlen=max_sequence_len-1, \n",
    "                                    padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list),\n",
    "                                            axis=1)   \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"../in/news_data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're then going to load the data one at a time and append *only* the headlines to our list of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if 'Comments' in filename:\n",
    "        comment_df = pd.read_csv(data_dir + \"/\" + filename)\n",
    "        all_comments.extend(list(comment_df[\"commentBody\"].values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then clean up a little bit and see how many data points we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418481"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments = [c for c in all_comments if c != \"Unknown\"] # remove all unknown headlines\n",
    "len(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sample from all_comments\n",
    "import random\n",
    "sample_comments = random.sample(all_comments, 100)\n",
    "len(sample_comments)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call out ```clean_text()``` function and then inspect the first 10 texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the pension bomb is real for many categories of public retirees especially police and fire  your perception of the teacher glide path being stressful  actually thats the private sector as well  i greatly value all who perform honest work including teachers and public employees  but why should public employees of any category have it easier or better than the general working population that is footing the bill',\n",
       " 'its beautiful ',\n",
       " 'a signet is also called a sealbra hrefhttpswwwmerriamwebstercomdictionaryseal titlehttpswwwmerriamwebstercomdictionaryseal targetblankhttpswwwmerriamwebstercomdictionarysealabrbrb 1  a device with a cut or raised emblem symbol or word used especially to certify a signature or authenticate a document 2  a medallion or ring face bearing such a device incised so that it can be impressed on wax or moist clay',\n",
       " 'trump also likes medals remember the purple heart he was given so he should probably award himself the presidential medal of freedom for his fantasy of service in the parkland shooting then comes the congressional medal of honor for the heroism he would have exhibited in vietnam were it not for those pesky bone spurs ',\n",
       " 'even more selfserving is producing insinuations as listed  in memo without presenting any evidence willynilly tarring people and institution for political reasonsbrbrwait for the counter memo',\n",
       " 'i am a person who does not really like to travel i was born in north carolina my parents were born in north carolina their parents were born in north carolina my family has lived here since the 1800s and i love it i love the relaxing beaches the hot sun and the people so this being said i would visit buffalo new york i would pick this place because it is out of my comfort zone but not too much like prague or iceland and i would not be worried about whether or not someone can speak my language i have not been to any of the places on the list but who knows i might be a late bloomer on traveling i would definitely recommend putting california on the list even though it is pretty similar to where i live i have never been there and it is expensive it has always struck me as somewhere i would never get tired of a place to relax is more for me than an adventurous place i can appreciate an adventure but i have never wanted to climb a mountain or anything like that if i could go anywhere for a vacation it would be california ',\n",
       " 'yes of course i only lied for all those years because i was taking care of my people ',\n",
       " 'the press conference is sick making everyone is focused on the wrong thingsbrthe only solution is a return to the assault weapons banbrthe rest of the hyperbole is dangerous most cops are unable to remain objective and detached when giving a traffic ticket i certainly dont want them searching all that i have said for things they can spin into useful evidence to harass or jail me brbronce again you cannot predict these things you cannot prevent these things from happening the only thing you can reasonably do in a free society is to restrict access to the weapons used  those are the only facts that should be focused on here and in any similar event anything else is grandstanding pie in the sky bologna brbrit would also be reasonable to mandate that gun owners have a safe to store their weapons in or we could do as chris rock once suggested charge 500 per bullet that doesnt account for the people who reload their brass but it sure would restrict the numbers of mass shootingsbrbrid also suggest we turn our gaze towards the politics of the last 40 years we never had this problem with frequent mass shootings before the reagan republicans destroyed our government by the people and for the people turning it into government by and for the one percent all of our protection have been taken away and the one agency created to fix that since reagan has now been taken over and hamstrung by its administrator in exactly the same way reagans criminal cabal did it in the 80s  ',\n",
       " 'mr tomasky is generously forgiving in assessing orrin hatch as a decent man in an indecent dynamic but i think we have to hold our lawmakers to the highest standards of personal integrity to dedication to the common good  time was i thought mr hatch fit the bill but the political playacting of recent years mr tomasky recounts here is a shameless betrayal of everything edward kennedy stood for as a fellow senator  when i hear mr hatch recite gop talking points i can only sigh  he used to have principle along with ambition but his ambition spawned a preening vanity that ultimately trumped principle  what were left with is just another suit bespoke but empty',\n",
       " 'it took trump about 1 year to reverse the anemic 15 gdp growth under the obama socialist regime but to his credit it is done the engine of capitalism has been released upon the world thanks to trump and his policies which include clean coal arctic drilling fracking lower income taxes lower corporate taxes less regulation new off shore drilling and signing out of the paris accords kudos to trump obama had the economy in chains for 8 long years and mr trump has released us from the socialist shackles ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [clean_text(x) for x in sample_comments]\n",
    "corpus[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize\n",
    "\n",
    "We're then going to tokenize our data, using the ```Tokenizer()``` class from ```TensorFlow```, about which you can read more [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer).\n",
    "\n",
    "We then use the ```get_sequence_of_tokens()``` function we defined above, which turns every text into a sequence of tokens based on the vocabulary from the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code creates an index of the words in the corpus\n",
    "tokenizer = Tokenizer()\n",
    "## tokenization\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1 # +1 accounts for words that arent in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 708],\n",
       " [1, 708, 709],\n",
       " [1, 708, 709, 7],\n",
       " [1, 708, 709, 7, 390],\n",
       " [1, 708, 709, 7, 390, 11],\n",
       " [1, 708, 709, 7, 390, 11, 69],\n",
       " [1, 708, 709, 7, 390, 11, 69, 710],\n",
       " [1, 708, 709, 7, 390, 11, 69, 710, 5],\n",
       " [1, 708, 709, 7, 390, 11, 69, 710, 5, 83],\n",
       " [1, 708, 709, 7, 390, 11, 69, 710, 5, 83, 711]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take input and turn it into numerical output\n",
    "inp_sequences = get_sequence_of_tokens(tokenizer, corpus)\n",
    "inp_sequences[:10]\n",
    "# the length of the input sequences are defined by how the words relate to each other"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then want to *pad* our input sequences to make them all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding makes different inputs the same length as the longest input by adding 0's where words are missing in inputs\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
    "# E.g. with \"My cat\" and \"The big dog\" a 0 would be added in the front like \"0 My cat\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the ```create_model()``` function created above to initialize a model, telling the model the length of sequences and the total size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 263, 10)           24090     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               44400     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2409)              243309    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 311,799\n",
      "Trainable params: 311,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 12:22:46.441197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-24 12:22:46.443836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-24 12:22:46.445864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training is exactly the same as last week, but instead of document labels, we're fitting the model to predict next word.\n",
    "\n",
    "*NB!* This will take some time to train! It took me 35 minutes on UCloud 32xCPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 12:22:51.462663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-24 12:22:51.465472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-24 12:22:51.467542: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-24 12:22:52.610936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-24 12:22:52.613998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-24 12:22:52.616886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 24s 382ms/step - loss: 7.2937\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 23s 434ms/step - loss: 6.7114\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 23s 426ms/step - loss: 6.6454\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 23s 425ms/step - loss: 6.6069\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 23s 431ms/step - loss: 6.5649\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 23s 424ms/step - loss: 6.5206\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 23s 425ms/step - loss: 6.4808\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 22s 422ms/step - loss: 6.4421\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 22s 421ms/step - loss: 6.4105\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 23s 429ms/step - loss: 6.3810\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 22s 423ms/step - loss: 6.3519\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 23s 428ms/step - loss: 6.3204\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 23s 438ms/step - loss: 6.2892\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 24s 453ms/step - loss: 6.2580\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 30s 558ms/step - loss: 6.2291\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 29s 539ms/step - loss: 6.1975\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 29s 544ms/step - loss: 6.1667\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 28s 535ms/step - loss: 6.1313\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 26s 494ms/step - loss: 6.1014\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 26s 486ms/step - loss: 6.0696\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 26s 483ms/step - loss: 6.0375\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 25s 469ms/step - loss: 6.0027\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 24s 462ms/step - loss: 5.9673\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 26s 491ms/step - loss: 5.9303\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 27s 503ms/step - loss: 5.8974\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 26s 495ms/step - loss: 5.8624\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 929s 18s/step - loss: 5.8258\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 30s 564ms/step - loss: 5.7885\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 26s 486ms/step - loss: 5.7535\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 29s 544ms/step - loss: 5.7124\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 28s 538ms/step - loss: 5.6764\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 27s 499ms/step - loss: 5.6404\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 27s 510ms/step - loss: 5.6032\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 31s 576ms/step - loss: 5.5643\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 24s 460ms/step - loss: 5.5289\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 18s 341ms/step - loss: 5.4878\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 5.4516\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 5.4120\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 17s 326ms/step - loss: 5.3713\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 5.3360\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 5.2955\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 5.2549\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 5.2128\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 5.1745\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 17s 314ms/step - loss: 5.1373\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 17s 316ms/step - loss: 5.0985\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 17s 314ms/step - loss: 5.0594\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 5.0209\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 17s 316ms/step - loss: 4.9816\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 17s 319ms/step - loss: 4.9424\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 17s 316ms/step - loss: 4.8952\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 17s 329ms/step - loss: 4.8645\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 4.8195\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 17s 322ms/step - loss: 4.7807\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 17s 319ms/step - loss: 4.7432\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 17s 319ms/step - loss: 4.7020\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 4.6648\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 17s 318ms/step - loss: 4.6284\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 4.5856\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 17s 324ms/step - loss: 4.5516\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 17s 322ms/step - loss: 4.5075\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 4.4718\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 4.4333\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 17s 318ms/step - loss: 4.3935\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 4.3531\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 4.3215\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 4.2848\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 17s 316ms/step - loss: 4.2468\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 17s 323ms/step - loss: 4.2157\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 17s 318ms/step - loss: 4.1718\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 17s 318ms/step - loss: 4.1430\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 17s 325ms/step - loss: 4.0990\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 17s 318ms/step - loss: 4.0651\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 17s 319ms/step - loss: 4.0331\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 3.9964\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 17s 326ms/step - loss: 3.9688\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 3.9261\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 17s 316ms/step - loss: 3.8963\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 3.8610\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 17s 318ms/step - loss: 3.8241\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 17s 319ms/step - loss: 3.7993\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 17s 318ms/step - loss: 3.7624\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 3.7305\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 17s 316ms/step - loss: 3.6895\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 3.6597\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 17s 322ms/step - loss: 3.6200\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 17s 327ms/step - loss: 3.6039\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 3.5636\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 3.5373\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 3.5045\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 3.4776\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 17s 319ms/step - loss: 3.4483\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 17s 322ms/step - loss: 3.4286\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 17s 320ms/step - loss: 3.3852\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 3.3539\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 3.3311\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 3.3000\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 3.2662\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 17s 321ms/step - loss: 3.2461\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 17s 317ms/step - loss: 3.2199\n"
     ]
    }
   ],
   "source": [
    "# creating history of the model\n",
    "history = model.fit(predictors, \n",
    "                    label, \n",
    "                    epochs=100,\n",
    "                    batch_size=128, \n",
    "                    verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model has trained, we can then use this to generate *new text*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 13:11:58.672912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-24 13:11:58.675595: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-24 13:11:58.677490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 761ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Danish The World Latestage Capitalism The\n"
     ]
    }
   ],
   "source": [
    "# print text based on the word/words and what the model has predicted would go along with it\n",
    "print(generate_text(\"danish\", 5, model, max_sequence_len)) # the 5 is the number of words we want to come after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kwargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# saving\u001b[39;00m\n\u001b[1;32m      2\u001b[0m outpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m../out/rnn_model.joblib\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39msaving\u001b[39m.\u001b[39msave_model(model, outpath, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_format\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kwargs' is not defined"
     ]
    }
   ],
   "source": [
    "# saving\n",
    "outpath = os.path.join(\"../out/rnn_model.joblib\")\n",
    "tf.keras.saving.save_model(model, outpath, overwrite=True, save_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 13:19:41.153698: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:41.153817: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:41.153910: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:41.270162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:41.270277: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:41.270370: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:41.704891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:41.705008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:41.705105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:41.904324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:41.904440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:41.904533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:42.019969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:42.020094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:42.020187: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:42.098833: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:42.098949: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:42.099043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:42.386667: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:42.386782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:42.386876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:42.679487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:42.679602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:42.679695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:42.762427: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:42.762546: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:42.762640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:43.299082: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:43.299197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:43.299290: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:43.432997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-03-24 13:19:43.433111: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-03-24 13:19:43.433205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-03-24 13:19:44.225580: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-24 13:19:44.228043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-24 13:19:44.229557: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# importing\n",
    "new_model = tf.keras.models.load_model(\"../out/rnn_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 589ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 13:20:18.562771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-24 13:20:18.565668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-24 13:20:18.567803: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Danish The World Latestage Capitalism The\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"danish\", 5, new_model, max_sequence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import dump\n",
    "# saving trained model\n",
    "dump(history, \"../out/rnn_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 14:26:42.620445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-22 14:26:42.623448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-22 14:26:42.625440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Danish Inventor Is Found Guilty In\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = joblib.load(\"../out/rnn_model.joblib\")\n",
    "print(generate_text(\"danish\", 5, model, max_sequence_len))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained word embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having the embedding layer as a trainable parameter, we can instead using a *pretrained word embedding* model like ```word2vec```.\n",
    "\n",
    "In the following examples, we're using [GloVe embeddings](https://nlp.stanford.edu/projects/glove/). These are trained a little differently from ```word2vec``` but they behave in the same way."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make use of already trained word embeddings, which are better than what we ever could train on a model ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m         word, coefs \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(maxsplit\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m         coefs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfromstring(coefs, \u001b[39m\"\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m         embeddings_index[word] \u001b[39m=\u001b[39m coefs\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFound \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m word vectors.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(embeddings_index))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# defining path\n",
    "path_to_glove_file = os.path.join(\"../data/glove/\")\n",
    "\n",
    "# creating pre-trained word embedding index\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define some variables that we're going to use later.\n",
    "\n",
    "With hits and misses, we're counting how many words in the corpus vocabulary have a corresponding GloVe embedding; misses are the words which appear in our vocabulary but which do not have a GloVe embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = total_words\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer - notice that this is different\n",
    "    model.add(Embedding(\n",
    "            total_words,\n",
    "            embedding_dim,\n",
    "            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "            trainable=False,\n",
    "            input_length=input_len)\n",
    "    )\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(500))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, \n",
    "                    activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                    optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(predictors, \n",
    "                    label, \n",
    "                    epochs=100,\n",
    "                    batch_size=128, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (generate_text(\"china\", 30, model, max_sequence_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
